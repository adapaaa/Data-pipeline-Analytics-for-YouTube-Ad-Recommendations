# Data-pipeline-Analytics-for-YouTube-Ad-Recommendations

ABSTRACT:
The explosion of online video content has led to an increased demand for tools and techniques to analyze viewer engagement, preferences, likings, and behavior. In this project, we explore the building of a serverless cloud-based data pipeline on AWS to analyze YouTube video statistics and draw key insights. Our pipeline leverages a range of AWS services, including Amazon S3 for data storage, AWS Lambda for serverless computing, Amazon Glue, Crawlers for data cataloging and Amazon Quicksight for data visualization.
Our pipeline enables the ingestion of YouTube data into our pipeline via AWS Command Line Interface, and which is then stored in Amazon S3. From there, the data is transformed using AWS Lambda and AWS Glue Studio and loaded into AWS Athena for analysis. Our pipeline also incorporates Tableau, providing users with an interactive dashboard to explore the insights generated from the data.
Through our implementation, we are able to analyze a range of video analytics metrics, including views, likes, tags, and sentiment. Our pipeline also provides insights into audience demographics and geographic distribution, enabling content creators and marketers to better understand their viewership and tailor their content to meet their needs.
Overall, our data pipeline on AWS provides a scalable and flexible solution for analyzing YouTube video analytics, with the potential for further customization and integration with other data sources.

PROBLEM STATEMENT:
This project is inspired by the work of data engineers, who are responsible for making raw data more useful to the enterprise. The role requires a broad set of technical skills alongside the ability to communicate across departments that allow the data engineer to understand what business leaders want to gain from the company’s data sets. 
In addition to it, the rise of big data has led to an increased demand for scalable and efficient solutions for storing, processing, and analyzing data. As organizations strive to make sense of the vast amounts of data generated by their operations, they require powerful tools and technologies that can enable them to gain valuable insights and make informed decisions.
In response to this need, we have undertaken a capstone project to build a data pipeline on AWS. Our inspiration for this project comes from the recognition that AWS provides a wide range of services and tools that can be leveraged to develop a flexible and robust data pipeline that can handle diverse data types and support a range of analytics applications.
In this project we choose YouTube video dataset. YouTube, a platform which was founded as a free video sharing website in 2005, after spending a year focused on growing its user-base and make its presence felt globally; in 2008 it turned its focus on creating advertising formats that enabled its subscribers to monetize from their content on the site. While this was widely approved by its user community it was the following acquisition of DoubleClick which enabled Google to build an advertising ecosystem on YouTube.
YouTube tools today states that its advertisers currently have a reach to 2.476 billion users on YouTube daily, making it the world’s 2nd most ‘active’ social media platforms. Moreover, tools show that YouTube’s active users have grown quickly over the past years. The total number of users that advertisers can reach with ads on YouTube increased by roughly 185 million (-3.4%) in the twelve months leading up to July 2022.
With this project we built a serverless completely cloud-based data pipeline using various ETL, Big Data, Data Warehousing, Data Analytics, Data Mining techniques. The pipeline provides key insights and poses as a recommender model to recommend an appropriate AD for each video according to the most viewed category in a particular region. 
 

DATASET:
Our dataset for the project consists of analytical data on a large set of daily trending YouTube videos spanning over several months and several regions saved in several file formats. The dataset majorly consolidated into 2 different file formats. 
Firstly, a set of 10 csv files separately for each region: United States (US), Great Britain (GB), Denmark (DE), California (CA), Russia (RU), Mexico (MX), South Korea (KR), Japan (JP), India (IN) and France (FR). Each CSV file lists details regarding the variables title, channel title, category_id, publishing time, tags, views, likes and dislikes, description, and comment count for each video in it.
Secondly, a set of 10 JSON files separately for each region listed above: consisting of information related to what categories are associated with each category_id, which again varies from region to region.    
